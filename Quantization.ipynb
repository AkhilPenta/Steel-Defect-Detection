{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Post-Training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9XA1yCITUNva"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sp8hxw8TxB0",
    "outputId": "8e35cbe3-e205-45d4-ad43-bcef42ca23c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "enHHKyoyTu6Z"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/cs2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8TwpJYlVf_u_"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/titericz/building-and-visualizing-masks\n",
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "\n",
    "#defining function for converting EncodedPixels(rle: run length encoding) to mask\n",
    "def rle2mask(rle_string, img_shape=(256,1600)):\n",
    "    '''\n",
    "    input: EncodedPixels (run-length-encoded) string & image shape:-(width,height)\n",
    "    output: mask in numpy.ndarray format with shape (256,1600)\n",
    "    '''\n",
    "    rle_array = np.array([int(s)for s in rle_string.split()])\n",
    "    starts_array = rle_array[::2]-1\n",
    "    lengths_array = rle_array[1::2]\n",
    "    mask_array = np.zeros(img_shape[0]*img_shape[1],dtype=np.uint8)\n",
    "    #print(starts_array,lengths_array)\n",
    "    for i in range(len(starts_array)):\n",
    "        mask_array[starts_array[i]:starts_array[i]+lengths_array[i]] = 1\n",
    "    #order='F' because encoded pixels are numbered from top to bottom, then left to right\n",
    "    return mask_array.reshape(img_shape, order = 'F')\n",
    "\n",
    "#defining function for converting given mask to EncodedPixels(rle: run length encoding)\n",
    "def mask2rle(mask_array):\n",
    "    '''\n",
    "    input: mask in numpy.ndarray format\n",
    "    output: EncodedPixels (run-length-encoded) string\n",
    "    '''\n",
    "    mask_array = mask_array.T.flatten()\n",
    "    mask_array = np.concatenate([[0], mask_array, [0]])\n",
    "    rle_array = np.where(mask_array[1:]!=mask_array[:-1])[0]+1\n",
    "    rle_array[1::2] -= rle_array[::2]\n",
    "    rle_string = ' '.join(map(str,rle_array))\n",
    "    return rle_string\n",
    "\n",
    "#defining function for calculation of metric dice coefficient\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.math.reduce_sum(y_true_f * y_pred_f)\n",
    "    smoothing_const = 1e-9\n",
    "    return (2. * intersection + smoothing_const) / (tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f) + smoothing_const)\n",
    "\n",
    "#defining function for calculation of loss function: binary cross entropy + dice loss\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred) + (1-dice_coefficient(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzdgRbcYf7zU"
   },
   "outputs": [],
   "source": [
    "#Loading Unet++ trained model\n",
    "objects = {'bce_dice_loss':bce_dice_loss, 'dice_coefficient': dice_coefficient}\n",
    "model = tf.keras.models.load_model(path + 'unet_pp.h5', custom_objects = objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztZu9amROavh",
    "outputId": "9861b743-8667-4113-9e4f-5c9900b945b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmps4o5z6c1/assets\n"
     ]
    }
   ],
   "source": [
    "#Applying post-training quantization technique to our trained 'UNet++' model \n",
    "#https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "\n",
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WyAVqjWQM5v",
    "outputId": "9b9a1992-d484-44f4-d378-7554be9c17ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321360"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the lite model\n",
    "open(path+ 'tflite_model.tflite', \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eWgPKNwcT9U"
   },
   "source": [
    "### 12.2 Size Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0K6OoymPcUf"
   },
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size\n",
    "\n",
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
    "    elif unit == \"MB\":\n",
    "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2URpheTUfnVi",
    "outputId": "5c571bd6-2635-4c02-c5a5-95fe87f36e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 973.109 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(path + 'unet_pp.h5'), \"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdN8Hlk9QZaV",
    "outputId": "50b4a463-a795-40a2-e0d1-0830b2112d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 313.828 Kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(path+'tflite_model.tflite'), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbBi47NzcYlY"
   },
   "source": [
    "### 12.3 performance comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tUmN7YGzRfs4"
   },
   "outputs": [],
   "source": [
    "#function to evaluate the performance of tf keras model\n",
    "def evaluate_model(X, Y):\n",
    "    '''\n",
    "    X: List of Image Ids\n",
    "    Y: List of tuples(containing rles of actual/ground-truth masks) for the corresponding Image Ids\n",
    "    returns: dice-coeeficient calculated based on the the predictions\n",
    "    '''        \n",
    "    \n",
    "    smoothing_const = 1e-9\n",
    "    intersection = 0\n",
    "    denominator = 0\n",
    "    batch = np.empty((10,256,1600,3),dtype=np.float32)\n",
    "    y_actual_masks = np.empty((10,256,1600,4),dtype=np.uint8)\n",
    "\n",
    "    for i in range(0,len(X),10):\n",
    "        batch_idcs =  list(range(i, min(len(X), i + 10)))\n",
    "        if len(batch_idcs)== 10:        \n",
    "            for i, idx in enumerate(batch_idcs):\n",
    "                img = Image.open( path + 'data/train_images/' + X[idx])\n",
    "                batch[i,] = img#input image\n",
    "        else:\n",
    "            batch = np.empty((len(batch_idcs),256,1600,3),dtype=np.float32)\n",
    "            for i, idx in enumerate(batch_idcs):\n",
    "                img = Image.open( path + 'data/train_images/' + X[idx])\n",
    "                batch[i,] = img#input image\n",
    "            y_actual_masks = np.empty((len(batch_idcs),256,1600,4),dtype=np.uint8) \n",
    "\n",
    "        y_pred_masks = model.predict(batch).round().astype(int)\n",
    "        \n",
    "        for j, idx in enumerate(batch_idcs):\n",
    "            y_actual_masks[j,:,:,0] = rle2mask(Y[idx][0])\n",
    "            y_actual_masks[j,:,:,1] = rle2mask(Y[idx][1])\n",
    "            y_actual_masks[j,:,:,2] = rle2mask(Y[idx][2])\n",
    "            y_actual_masks[j,:,:,3] = rle2mask(Y[idx][3])\n",
    "        \n",
    "        #batchwise calculation for dice coefficient\n",
    "        y_true = y_actual_masks.flatten()\n",
    "        y_pred = y_pred_masks.flatten()\n",
    "        intersection  = intersection + (np.sum(y_true * y_pred))\n",
    "        denominator  = denominator + (np.sum(y_true) + np.sum(y_pred))\n",
    "    dc = (2*intersection + smoothing_const)/(denominator+smoothing_const)\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Faip4KgWVENl"
   },
   "outputs": [],
   "source": [
    "#function to evaluate the performance of lite model\n",
    "def evaluate_lite_model(X, Y):\n",
    "    '''\n",
    "    X: List of Image Ids\n",
    "    Y: List of tuples(containing rles of actual/ground-truth masks) for the corresponding Image Ids\n",
    "    returns: dice-coeeficient calculated based on the the predictions\n",
    "    '''        \n",
    "    interpreter = tf.lite.Interpreter(model_path = path + 'tflite_model.tflite')\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    interpreter.resize_tensor_input(input_details[0]['index'], (10, 256,1600,3))\n",
    "    interpreter.resize_tensor_input(output_details[0]['index'], (10, 256,1600,4))\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    smoothing_const = 1e-9\n",
    "    intersection = 0\n",
    "    denominator = 0\n",
    "    batch = np.empty((10,256,1600,3),dtype=np.float32)\n",
    "    y_actual_masks = np.empty((10,256,1600,4),dtype=np.uint8)\n",
    "    \n",
    "    for i in range(0,len(X),10):\n",
    "        batch_idcs =  list(range(i, min(len(X), i + 10)))\n",
    "        if len(batch_idcs)== 10:        \n",
    "            for i, idx in enumerate(batch_idcs):\n",
    "                img = Image.open( path + 'data/train_images/' + X[idx])\n",
    "                batch[i,] = img#input image\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], batch)\n",
    "            interpreter.invoke()\n",
    "            y_pred_masks = interpreter.get_tensor(output_details[0]['index']).round().astype(int)\n",
    "\n",
    "        else:\n",
    "            batch = np.empty((len(batch_idcs),256,1600,3),dtype=np.float32)\n",
    "            for i, idx in enumerate(batch_idcs):\n",
    "                img = Image.open( path + 'data/train_images/' + X[idx])\n",
    "                batch[i,] = img#input image\n",
    "            interpreter.resize_tensor_input(input_details[0]['index'], (len(batch_idcs), 256,1600,3))\n",
    "            interpreter.resize_tensor_input(output_details[0]['index'], (len(batch_idcs), 256,1600,4))\n",
    "            interpreter.allocate_tensors()\n",
    "            interpreter.set_tensor(interpreter.get_input_details()[0]['index'], batch)\n",
    "            interpreter.invoke()\n",
    "            y_pred_masks = interpreter.get_tensor(interpreter.get_output_details()[0]['index']).round().astype(int)\n",
    "            y_actual_masks = np.empty((len(batch_idcs),256,1600,4),dtype=np.uint8)\n",
    "\n",
    "        \n",
    "        for j, idx in enumerate(batch_idcs):\n",
    "            y_actual_masks[j,:,:,0] = rle2mask(Y[idx][0])\n",
    "            y_actual_masks[j,:,:,1] = rle2mask(Y[idx][1])\n",
    "            y_actual_masks[j,:,:,2] = rle2mask(Y[idx][2])\n",
    "            y_actual_masks[j,:,:,3] = rle2mask(Y[idx][3])\n",
    "        \n",
    "        #batchwise calculation for dice coefficient\n",
    "        y_true = y_actual_masks.flatten()\n",
    "        y_pred = y_pred_masks.flatten()\n",
    "        intersection  = intersection + (np.sum(y_true * y_pred))\n",
    "        denominator  = denominator + (np.sum(y_true) + np.sum(y_pred))\n",
    "    dc = (2*intersection + smoothing_const)/(denominator+smoothing_const)\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cNzXEJxzgw2w"
   },
   "outputs": [],
   "source": [
    "#loading Validation Data dataframe\n",
    "vali_data = pd.read_csv(path + \"data/validtn_data.csv\").fillna('')\n",
    "x= vali_data['ImageId'].tolist()\n",
    "y = list(vali_data[['rle_1', 'rle_2', 'rle_3', 'rle_4']].to_records(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lw3yLmLRTgwS"
   },
   "outputs": [],
   "source": [
    "#loading original model\n",
    "model = tf.keras.models.load_model(path + 'unet_pp.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vdd0Rse2enEm",
    "outputId": "a5fbde1c-a287-4b8d-d584-241d2d119643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient for validation data:  0.5872662331855102\n"
     ]
    }
   ],
   "source": [
    "# checking performance of unet_pp.h5\n",
    "dice_coeff = evaluate_model(x[0:100], y[0:100])\n",
    "print('Dice Coefficient for validation data: ', dice_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uo-OE0vWf5k",
    "outputId": "d0dd4e59-5a4a-4684-a65b-cd8222559c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [   1  256 1600    3]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [   1  256 1600    4]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "#loading lite model\n",
    "interpreter = tf.lite.Interpreter(model_path = path + 'tflite_model.tflite')\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23QvbijeqpU",
    "outputId": "27ff345b-a5d2-4bdc-bea1-0aef4a2ba7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient for validation data:  0.5880486725401608\n"
     ]
    }
   ],
   "source": [
    "# checking performance of tflite model\n",
    "dice_coeff = evaluate_lite_model(x[0:100], y[0:100])\n",
    "print('Dice Coefficient for validation data: ', dice_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9SkfjHbRba1"
   },
   "source": [
    "Size reduced by almost 3 times and but the performance is almost same."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Quantization Draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
